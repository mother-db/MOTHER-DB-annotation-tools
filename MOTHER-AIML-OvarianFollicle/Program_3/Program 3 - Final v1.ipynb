{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a92b5185-4e79-4eb1-bd0e-96d08dc17193",
   "metadata": {},
   "source": [
    "# Program 3\n",
    "v5.1\n",
    "\n",
    "Adapted from previous iterations by Colette and Param."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de46ac58-11c1-4e73-a864-5f2d7efa0158",
   "metadata": {},
   "source": [
    "## Base Setup\n",
    "\n",
    "This section contains the basic environment set up for this notebook, including imports, constants, and any variable that needs to be easily accessed for changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "903b9657-85ee-42a5-ab2a-ec388ed382a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import torch\n",
    "import torchvision\n",
    "import os\n",
    "import datetime\n",
    "import shutil\n",
    "import platform\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from torchvision import datasets, transforms, models\n",
    "from torch.utils.data import DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.utils import shuffle\n",
    "from numpy.random import choice\n",
    "from ipylab import JupyterFrontEnd\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd3a464f-9a82-434d-912e-2c9d0fd8c5dd",
   "metadata": {},
   "source": [
    "This is a set of constants used mainly for workspace setup.\n",
    "\n",
    "`TRAINING_DATA`: The relative or absolute path to the directory containing the training data.\\\n",
    "`CHECKPOINT`: The base name of the model checkpoint file to create. Will be modified later for checkpoint saving. Current version of the program expects \"epoch_\" or some other similar 6 characters at the end when not saving each epoch.\\\n",
    "`OUTPUT_DIR`: The absolute path from the current directory to the directory to be used for output files made by this notebook. <b>Note:</b> The directory structure may already exist, but it does not need to. A later function will make it if it does not exist.\\\n",
    "`NOTEBOOK_NAME`: The exact name of this notebook, including the file extension. Needed later for programmatic html conversion and copying of the notebook.\\\n",
    "`SAVED_FILES`: Not technically a constant, but should not be altered by user. Used to keep track of any non-checkpoint file that gets saved to later move to output.\\\n",
    "`APP`: JupyterFrontEnd instance that is used to save the notebook programmatically later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc14f122-43b0-4e53-bbaf-dc6722ed1361",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define constants\n",
    "TRAINING_DATA = \"../../Data/Training/Primordial/v10/\"\n",
    "CHECKPOINT = \"Resnet34_200px_v10_test_epoch_\"\n",
    "OUTPUT_DIR = \"Output/Testing/Run Whatever/\"\n",
    "NOTEBOOK_NAME = \"Program 3 - Final v1.ipynb\" #Make sure this is identical to the name of THIS notebook\n",
    "SAVED_FILES = [] #Leave as an empty list\n",
    "APP = JupyterFrontEnd() #Needed to save the notebook programmatically later, do not change."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb5ee426-68d4-4588-828f-c6ad4f3ae321",
   "metadata": {},
   "source": [
    "These are variables and flags for functions that get used later.\n",
    "\n",
    "`transform`: The set of torchvision transforms to be applied to training images before they are input into the model.\\\n",
    "`batch_size`: The amount of images per DataLoader batch. Heavily affects VRAM usage. Speed testing has determined 128 to be optimal for my hardware.\\\n",
    "`num_workers`: The amount of workers for the DataLoader to use to parallelize training. Affects system RAM usage. Speed testing has determined 16 to be optimal for my hardware. <b>Note:</b> Windows is incapable of parallelizing Jupyter Notebooks like this; therefore, this variable will be set to 0 if on Windows.\\\n",
    "`freeze_model`: Flag to determine whether or not to freeze all layers of the model except the final layer. Testing has shown better prediction performance with this set to False.\\\n",
    "`use_class_weights`: Flag to determine whether or not to pass the calculated weights of each class to the loss function. Testing has shown better prediction performance with this set to True.\\\n",
    "`sgd_learning_rate`: The learning rate to give to the sgd optimizer. Testing has shown 0.00007 to be the best performing value for learning rate with the current training data set.\\\n",
    "`sgd_momentum`: The momentum to give to the sgd optimizer. Testing has shown an inconclusive effect on prediction performance. Using 0.9 for current training data set.\\\n",
    "`sgd_weight_decay`: The weight decay value to give to the sgd optimizer. Testing has shown an inconclusive effect on prediction performance. Using 0.01 for current training data set.\\\n",
    "`num_epochs`: The number of epochs to train for. Total number of epochs run will be this + 1 due to running an untrained epoch 0 for control purposes.\\\n",
    "`save_each_epoch`: Flag to determine whether to save a checkpoint for every epoch or only the epochs that have the best accuracy and loss values.\\\n",
    "`use_amp`: Flag to determine whether or not to use PyTorch's Automatic Mixed Precision. Can significantly boost performance with minimal cost to calculation accuracy.\\\n",
    "`save_figs`: Flag to determine whether to save any extra figures created in this notebook for analysis purposes. Checkpoints will still be saved regardless."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15451239-6ba3-4be8-9159-77b039b37c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define variables\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean = [0.5, 0.5, 0.5], std = [0.5, 0.5, 0.5])\n",
    "])\n",
    "\n",
    "batch_size = 128\n",
    "num_workers = 0 if platform.system() == \"Windows\" else 16\n",
    "\n",
    "freeze_model = False\n",
    "use_class_weights = True\n",
    "\n",
    "sgd_learning_rate = 0.00007\n",
    "sgd_momentum = 0.9\n",
    "sgd_weight_decay = 0.01\n",
    "\n",
    "num_epochs = 10\n",
    "save_each_epoch = True\n",
    "\n",
    "use_amp = True\n",
    "\n",
    "save_figs = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb56b151-73ec-4395-8b3d-dc45f9e26b0c",
   "metadata": {},
   "source": [
    "## Class and Function Declarations\n",
    "\n",
    "This section contains all the Classes and Functions used by this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5fd0621-5d93-45a6-8d2c-3980c967a75b",
   "metadata": {},
   "source": [
    "`ImageFolderWithPaths`: Class that extends `torchvision.datasets.ImageFolder`\n",
    "\n",
    "This class extends the base torchvision ImageFolder class to add the ability to return the path to the image alongside the image and its label.\n",
    "\n",
    "<b>Methods:</b>\\\n",
    "&emsp;`__getitem__`: Gets the item in the dataset at an index. Override.\n",
    "\n",
    "&emsp;<b>Parameters:</b>\\\n",
    "&emsp;&emsp;`index`: An index value to be used to get an item in the dataset.\n",
    "\n",
    "&emsp;Calls `super().__getitem__()` with the `index` parameter to get the image and label to be trained on.\\\n",
    "&emsp;Also gets the image path from `self.imgs`.\n",
    "\n",
    "&emsp;<b>Returns:</b>\\\n",
    "&emsp;&emsp;A tuple containing the image, its label, and its path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0409e679-f683-4252-be37-cb3b7d99d0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageFolderWithPaths(datasets.ImageFolder):\n",
    "    '''Image folder dataset class extending torchvision.datasets.ImageFolder'''\n",
    "    def __getitem__(self, index):\n",
    "        '''Gets the image and label at the given index. Returns them alongside the path to the image.'''\n",
    "        image, label = super(ImageFolderWithPaths, self).__getitem__(index)\n",
    "        path = self.imgs[index][0]\n",
    "        return (image, label, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fcc10d5-02fe-40dd-a40c-aafc2d35725f",
   "metadata": {},
   "source": [
    "`setup_model`: Function used to prepare the image classification model being used.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`model`: The image classification model to be setup.\\\n",
    "&emsp;`out_features`: The number of output features to use in the final layer of the model.\n",
    "\n",
    "If `freeze_model` flag is set to True, this function will loop through the existing layers of the model and prevent them from being altered during training.\\\n",
    "The function then replaces the fully connected layer of the model with a Linear layer that has a number of output features equal to `out_features`.\n",
    "\n",
    "<b>Returns:</b>\\\n",
    "&emsp;The modified model sent to the torch `device` being used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80004118-7cd8-4bd7-915c-b6cef27e6a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_model(model, out_features):\n",
    "    '''Applies desired modifications to given model. Returns model on torch device.'''\n",
    "    #Freeze model, if desired\n",
    "    if freeze_model:\n",
    "        for param in model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    #Replace final layer\n",
    "    model.fc = nn.Linear(model.fc.in_features, out_features)\n",
    "\n",
    "    return model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660c6cfd-36e9-4da5-9b47-8698c768c800",
   "metadata": {},
   "source": [
    "`train_model`: The main training loop for the model.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`model`: The already set up classification model to be trained.\\\n",
    "&emsp;`criterion`: The loss function for the model.\\\n",
    "&emsp;`optimizer`: The optimizer for the model.\\\n",
    "&emsp;`scheduler`: The learning rate scheduler for the model. <b>Default:</b> None.\\\n",
    "&emsp;`num_epochs`: The number of epochs to train for. <b>Default:</b> 10.\n",
    "\n",
    "Iterates through `num_epochs` + 1 number of epochs for training. Epoch 0 is used with 0 learning rate to test the pretrained/untrained model as a control.\\\n",
    "Further iterates between \"train\" and \"test\" phases for each epoch.\\\n",
    "Makes predictions on every image in the DataLoader for the current phase. If \"train\" phase, back propagates the losses and steps `optimizer` and `scheduler` if it exists. Losses and `optimizer` are wrapped by a `torch.amp.GradScaler` called `scaler` to account for and scale values according to the level of precision used for each layer of the model.\\\n",
    "Saves losses and accuracy percentages for each phase of each epoch. Also keeps track of which epochs had the lowest loss and highest accuracy.\\\n",
    "Saves checkpoints for either each epoch or only the best loss and accuracy epochs depending on the state of the `save_each_epoch` flag.\\\n",
    "Prints progress, loss, and accuracy during and after each epoch.\n",
    "\n",
    "<b>Returns:</b>\\\n",
    "&emsp;Dictionaries containing the per epoch losses and accuracies separated by phase (\"train\" or \"test\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab84215-d81c-421a-880e-7e56d5b92401",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler = None, num_epochs = 10):\n",
    "    '''Trains the given model using the given loss function and optimizer on the given train dataloader.\n",
    "    Tests the model's learning on the given test dataloader.\n",
    "    Runs for num_epochs epochs.\n",
    "    Returns train and test losses and accuracies as dictionaries of lists.'''\n",
    "    start_time = datetime.datetime.now()\n",
    "    \n",
    "    epoch_losses = {\n",
    "        'train': [],\n",
    "        'test': []\n",
    "    }\n",
    "    epoch_accuracies = {\n",
    "        'train': [],\n",
    "        'test': []\n",
    "    }\n",
    "\n",
    "    max_test_accuracy = 0.0\n",
    "    min_test_loss = np.inf\n",
    "    best_accuracy_epoch = 0\n",
    "    best_loss_epoch = 0\n",
    "    total_steps = image_dataloader_sizes['train']\n",
    "    learning_rate = optimizer.param_groups[0]['lr']\n",
    "\n",
    "    scaler = torch.amp.GradScaler(enabled = use_amp)\n",
    "\n",
    "    for epoch in range(num_epochs + 1):\n",
    "        epoch_start_time = datetime.datetime.now()\n",
    "        \n",
    "        #Set lr to 0 for epoch 0 and return to original lr after\n",
    "        if epoch == 0:\n",
    "            optimizer.param_groups[0]['lr'] = 0\n",
    "        elif epoch == 1:\n",
    "            optimizer.param_groups[0]['lr'] = learning_rate\n",
    "\n",
    "        print(\"Epoch: {} of {} - lr: {}\".format(epoch, num_epochs, optimizer.param_groups[0]['lr']))\n",
    "\n",
    "        #Iterate between train and test phases per epoch\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            #Iterate over data\n",
    "            for batch, (data, targets, _) in enumerate(image_dataloaders[phase]):\n",
    "                data, targets = data.to(device), targets.to(device)\n",
    "\n",
    "                #Zero gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                #Forward\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    with torch.autocast(device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\", enabled = use_amp):\n",
    "                        outputs = model(data)\n",
    "                        _, preds = torch.max(outputs, 1)\n",
    "                        loss = criterion(outputs, targets)\n",
    "\n",
    "                    #Backward\n",
    "                    if phase == 'train':\n",
    "                        scaler.scale(loss).backward()\n",
    "                        scaler.step(optimizer)\n",
    "                        scaler.update()\n",
    "\n",
    "                #Batch Stats\n",
    "                running_loss += loss.item() * data.size(0)\n",
    "                running_corrects += torch.sum(preds == targets.data)\n",
    "\n",
    "                #Print status during training\n",
    "                if batch % 1000 == 0 and phase == 'train':\n",
    "                    print(\"  Step: {} of {} - Loss: {:.4f}\".format(batch, total_steps, loss.item()))\n",
    "\n",
    "            #Step scheduler if it exists\n",
    "            if phase == 'train' and scheduler is not None:\n",
    "                scheduler.step()\n",
    "\n",
    "            #Epoch stats\n",
    "            epoch_losses[phase].append(running_loss / image_dataset_sizes[phase])\n",
    "            epoch_accuracies[phase].append((100 * running_corrects.double() / image_dataset_sizes[phase]).item())\n",
    "\n",
    "            print(\"  Phase: {}\".format(phase))\n",
    "            print(\"    Loss: {:.3f} - Mean Loss: {:.3f} - Accuracy: {:.1f}%\".format(epoch_losses[phase][epoch], np.mean(epoch_losses[phase]), epoch_accuracies[phase][epoch]))\n",
    "            \n",
    "            #Save model if network improved on test set\n",
    "            if phase == 'test' and epoch_accuracies[phase][epoch] > max_test_accuracy:\n",
    "                max_test_accuracy = epoch_accuracies[phase][epoch]\n",
    "                best_accuracy_epoch = epoch\n",
    "                print(\"****New Best Accuracy****\")\n",
    "\n",
    "                if not save_each_epoch:\n",
    "                    print(\"    Saving Checkpoint\")\n",
    "                    torch.save(model.state_dict(), CHECKPOINT[:-6] + \"best_accuracy.pt\")\n",
    "\n",
    "            if phase == 'test' and epoch_losses[phase][epoch] < min_test_loss:\n",
    "                min_test_loss = epoch_losses[phase][epoch]\n",
    "                best_loss_epoch = epoch\n",
    "                print(\"****New Best Loss****\")\n",
    "\n",
    "                if not save_each_epoch:\n",
    "                    print(\"    Saving Checkpoint\")\n",
    "                    torch.save(model.state_dict(), CHECKPOINT[:-6] + \"best_loss.pt\")\n",
    "\n",
    "            if save_each_epoch:\n",
    "                print(\"  **Saving Epoch Checkpoint**\")\n",
    "                torch.save(model.state_dict(), CHECKPOINT + str(epoch) + \".pt\")\n",
    "\n",
    "        #Print runtimes\n",
    "        epoch_end_time = datetime.datetime.now()\n",
    "        \n",
    "        print(\"  Epoch Time: {}\".format(epoch_end_time - epoch_start_time))\n",
    "        print(\"  Total Time: {}\\n\".format(epoch_end_time - start_time))\n",
    "\n",
    "    #Print total runtime and lowest test loss\n",
    "    print(\"Training finished in: {}\".format(datetime.datetime.now() - start_time))\n",
    "    print(\"  Best test accuracy: {:.1f}%\".format(max_test_accuracy))\n",
    "    print(\"  Best accuracy epoch: {}\".format(best_accuracy_epoch))\n",
    "    print(\"  Best test loss: {:.3f}\".format(min_test_loss))\n",
    "    print(\"  Best loss epoch: {}\".format(best_loss_epoch))\n",
    "    \n",
    "    return epoch_losses, epoch_accuracies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ca15f31-de6a-4c1c-a328-94c6061643c2",
   "metadata": {},
   "source": [
    "`make_output_dir`: Creates the base output directory defined by `OUTPUT_DIR`, adds a sub-directory based on `epoch` or `checkpoint` parameters if they exist, then creates a time-stamped directory within the subdirectory.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`epoch`: The epoch number to make an output folder for when `save_each_epoch` is True. Must be passed as a string. <b>Default:</b> None\\\n",
    "&emsp;`checkpoint`: The descriptor of the checkpoint, `best_accuracy` or `best_loss`, to make an output folder for when `save_each_epoch` is False. Must be passed as a string. <b>Default:</b> None\n",
    "\n",
    "Only one of `epoch` and `checkpoint` can be passed at once. If both are passed, the function will raise an error.\\\n",
    "First, makes the directory tree specified by `OUTPUT_DIR` if the final directory does not already exist.\\\n",
    "Then, creates a directory within `OUTPUT_DIR` based on the `epoch` or `checkpoint` that is passed. Saves this dir as `subdir`. If neither are passed, skips this step.\\\n",
    "Next, creates a directory within `subdir` that is time-stamped with the current date and time.\\\n",
    "Saves the time-stamped directory to a global constant `TIME_STAMP_OUTPUT_DIR` to be used in final cleanup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b872393-6056-413b-aedb-bf13bf744c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_output_dir(epoch = None, checkpoint = None):\n",
    "    '''Check if the directory specified by OUTPUT_DIR exists. Create directory if it does not exist.\n",
    "    Create directories for each epoch/checkpoint depending on passed parameters. Finally, create time-stamped directory within.'''\n",
    "    #Make sure only one of epoch and checkpoint are provided, not both\n",
    "    if epoch is not None and checkpoint is not None:\n",
    "        raise Exception(\"Only one of 'epoch' and 'checkpoint' can be passed at a time. Got values for both.\")\n",
    "        \n",
    "    #Get the current time to timestamp\n",
    "    time = datetime.datetime.now()\n",
    "    \n",
    "    #Create base output directory if it does not exist\n",
    "    if not os.path.exists(OUTPUT_DIR):\n",
    "        os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "    if epoch is not None:\n",
    "        #Create directory for current epoch if it does not exist\n",
    "        subdir = OUTPUT_DIR + \"Epoch \" + epoch + \"/\"\n",
    "        \n",
    "        if not os.path.exists(subdir):\n",
    "            os.mkdir(subdir)\n",
    "    elif checkpoint is not None:\n",
    "        #Create directory for current checkpoint if it does not exist\n",
    "        subdir = OUTPUT_DIR + checkpoint + \"/\"\n",
    "\n",
    "        if not os.path.exists(subdir):\n",
    "            os.mkdir(subdir)\n",
    "    else:\n",
    "        #If both epoch and checkpoint are not given, make subdir an empty string\n",
    "        subdir = \"\"\n",
    "    \n",
    "    #Define global scope constant\n",
    "    global TIME_STAMP_OUTPUT_DIR\n",
    "    TIME_STAMP_OUTPUT_DIR = subdir + time.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    \n",
    "    #Make time-stamped output directory\n",
    "    os.mkdir(TIME_STAMP_OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf06a35-f72c-4d15-8ed0-99d9d44a87a9",
   "metadata": {},
   "source": [
    "`train_test_graph`: Graphs the train and test loss/accuracy data from model training.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`data`: The dictionary containing both train and test data to graph.\\\n",
    "&emsp;`graph_type`: A string to represent which type of graph this is. (i.e. \"Loss\" or \"Accuracy\")\n",
    "\n",
    "Graphs the train and test data on separate lines on the same plot and adds a legend with labels.\\\n",
    "If `save_figs` flag is set to True, saves the graph as a png and keeps track of it within the `SAVED_FILES` list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f09d7f-65a9-4e69-beed-8ff7950558fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_graph(data, graph_type):\n",
    "    '''Graph the given data and save to a file. Determines whether graph is loss or accuracy based on graph_type.'''\n",
    "    global SAVED_FILES\n",
    "    \n",
    "    _, ax = plt.subplots(figsize = (10, 5))\n",
    "\n",
    "    ax.set_title(graph_type + \" Graph\")\n",
    "    ax.set_ylabel(graph_type)\n",
    "    ax.set_xlabel(\"Epoch\")\n",
    "\n",
    "    if graph_type == \"Accuracy\":\n",
    "        ax.set_yticks(range(0, 101, 10))\n",
    "\n",
    "    ax.plot(data['train'], label = \"Train\")\n",
    "    ax.plot(data['test'], label = \"Test\")\n",
    "\n",
    "    ax.legend()\n",
    "\n",
    "    if save_figs:\n",
    "        file = graph_type + \"_Graph.png\"\n",
    "\n",
    "        #Keep track of file\n",
    "        SAVED_FILES.append(file)\n",
    "        \n",
    "        plt.savefig(file)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e87efe16-323e-42ce-89fe-65188b0bbfd2",
   "metadata": {},
   "source": [
    "`dataloader_predictions`: Makes predictions on the given DataLoader phase.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`phase`: The phase of the DataLoader to make predictions using. (i.e. \"train\", \"test\", \"validate\")\n",
    "\n",
    "Iterates through the entire DataLoader for `phase` and makes predictions on every image.\\\n",
    "Saves filename, actual and predicted class, whether the prediction was the same as the actual class, and the probabilities for each class into a pandas DataFrame.\n",
    "\n",
    "<b>Returns:</b>\\\n",
    "&emsp;The predicted class labels, actual class labels, and the pandas DataFrame that was created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e983d1-d663-436e-958b-67c212e74467",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataloader_predictions(phase):\n",
    "    '''Makes predictions on the images contained in the dataloader for the given phase.\n",
    "    Returns predicted labels, true labels, and a dataframe compiling the prediction data.'''\n",
    "    predicted_labels = []\n",
    "    true_labels = []\n",
    "    \n",
    "    prediction_df_base = {\n",
    "        'Filename': [],\n",
    "        'True Class': [],\n",
    "        'Predicted Class': [],\n",
    "        'Prediction': [],\n",
    "        'Negative': [],\n",
    "        'Primordial': [],\n",
    "        'Transitional Primordial': [],\n",
    "        'Primary': [],\n",
    "        'Transitional Primary': [],\n",
    "        'Secondary': [],\n",
    "        'Multilayer': []\n",
    "    }\n",
    "\n",
    "    #Iterate over dataloader for phase\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        \n",
    "        for inputs, labels, filenames in image_dataloaders[phase]:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            with torch.autocast(device_type = \"cuda\" if torch.cuda.is_available() else \"cpu\", enabled = use_amp):\n",
    "                output = model(inputs)\n",
    "    \n",
    "            probabilities = (torch.exp(output) / torch.sum(torch.exp(output), 1).reshape(-1, 1)).data.cpu().numpy()\n",
    "            \n",
    "            output = (torch.max(torch.exp(output), 1)[1]).data.cpu().numpy()\n",
    "            predicted_labels.extend(output)\n",
    "            \n",
    "            labels = labels.data.cpu().numpy()\n",
    "            true_labels.extend(labels)\n",
    "    \n",
    "            prediction_df_base['Filename'].extend(list(filenames))\n",
    "            prediction_df_base['True Class'].extend(list(labels))\n",
    "            prediction_df_base['Predicted Class'].extend(list(output))\n",
    "            prediction_df_base['Prediction'].extend(list(output == labels))\n",
    "            prediction_df_base['Negative'].extend(list(probabilities[:, 0]))\n",
    "            prediction_df_base['Primordial'].extend(list(probabilities[:, 1]))\n",
    "            prediction_df_base['Transitional Primordial'].extend(list(probabilities[:, 2]))\n",
    "            prediction_df_base['Primary'].extend(list(probabilities[:, 3]))\n",
    "            prediction_df_base['Transitional Primary'].extend(list(probabilities[:, 4]))\n",
    "            prediction_df_base['Secondary'].extend(list(probabilities[:, 5]))\n",
    "            prediction_df_base['Multilayer'].extend(list(probabilities[:, 6]))\n",
    "\n",
    "    return predicted_labels, true_labels, pd.DataFrame(prediction_df_base)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6517ce-307e-459a-b178-a95740e2af4d",
   "metadata": {},
   "source": [
    "`make_confusion_matrix`: Creates a confusion matrix based on given predicted labels and actual labels and creates a diagonal confusion matrix based on the same data. Plots both.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`predictions`: The predicted labels used to create the confusion matrix.\\\n",
    "&emsp;`labels`: The actual labels used to create the confusion matrix.\\\n",
    "&emsp;`phase`: The subset of the training data set that was used to generate the predicted labels. (i.e. \"train\", \"test\", \"validate\")\n",
    "\n",
    "Creates confusion matrix using `predictions` and `labels`.\\\n",
    "Then, converts confusion matrix to percentages for easier viewing.\\\n",
    "Calls `plot_confusion_matrix` to display the full confusion matrix.\\\n",
    "Creates a diagonal confusion matrix where each category is modified to include the percentages for each class that is one class higher and lower than the actual class. Negative is excluded and the first and last classes only add the one higher and one lower class respectively.\\\n",
    "Then, calls `plot_confusion_matrix` to display the diagonal confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a80e3cf-02d5-4047-a5aa-038f6ca420bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_confusion_matrix(predictions, labels, phase):\n",
    "    '''Create a confusion matrix for given prediction and true labels. Determine which image set was used based on phase.\n",
    "    Plot the confusion matrix and a graph showing each class percentage with a +-1 class buffer.'''\n",
    "    conf_matrix = confusion_matrix(labels, predictions)\n",
    "    percentage_conf_matrix = conf_matrix.astype(np.float32) / np.sum(conf_matrix)\n",
    "\n",
    "    #Make confusion matrix percentage-based\n",
    "    for i in range(len(classes)):\n",
    "        percentage_conf_matrix[i, :] = percentage_conf_matrix[i, :] * 100 / np.sum(percentage_conf_matrix[i, :])\n",
    "\n",
    "    #Plot confusion matrix\n",
    "    plot_confusion_matrix(percentage_conf_matrix, phase)\n",
    "\n",
    "    #Make modified confusion matrix of diagonal percentages with one class up and down, excluding negative\n",
    "    percentage_conf_matrix_diagonal = []\n",
    "\n",
    "    for i in range(len(classes)):\n",
    "        if i == 0:\n",
    "            percentage_conf_matrix_diagonal.append([percentage_conf_matrix[i, i]])\n",
    "        elif i == 1:\n",
    "            percentage_conf_matrix_diagonal.append([percentage_conf_matrix[i, i] + percentage_conf_matrix[i, i + 1]])\n",
    "        elif i > 1 and i < 6:\n",
    "            percentage_conf_matrix_diagonal.append([percentage_conf_matrix[i, i] + percentage_conf_matrix[i, i + 1] + percentage_conf_matrix[i, i - 1]])\n",
    "        else:\n",
    "            percentage_conf_matrix_diagonal.append([percentage_conf_matrix[i, i] + percentage_conf_matrix[i, i - 1]])\n",
    "\n",
    "    percentage_conf_matrix_diagonal = np.array(percentage_conf_matrix_diagonal)\n",
    "\n",
    "    #Plot modified diagonal confusion matrix\n",
    "    plot_confusion_matrix(percentage_conf_matrix_diagonal, phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc7fb0f-22fc-40d5-aca9-30139930b4be",
   "metadata": {},
   "source": [
    "`plot_confusion_matrix`: Displays the given confusion matrix.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`conf_matrix`: Confusion matrix to display.\\\n",
    "&emsp;`phase`: The subset of training images used to create the confusion matrix. (i.e. \"train\", \"test\", \"validate\")\n",
    "\n",
    "Displays the given confusion matrix using the Seaborn heatmap function. Determines whether it is diagonal or not based on the numpy .shape attribute. Uses `phase` to determine which DataLoader was used.\\\n",
    "If `save_figs` flag is True, saves the confusion matrix as a png using `phase` as part of the filename and keeps track of file using `SAVED_FILES`.\\\n",
    "Determines whether the confusion matrix is the full or diagonal one based on its shape property."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f20fced-3459-4d90-8604-e6e2b9f29521",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(conf_matrix, phase):\n",
    "    '''Plots given confusion matrix and saves to a file. Determines which image set was used based on phase.'''\n",
    "    global SAVED_FILES\n",
    "    \n",
    "    class_labels = [\"Negative\", \"Primordial\", \"Transitional Primordial\", \"Primary\", \"Transitional Primary\", \"Secondary\", \"Multilayer\"]\n",
    "    \n",
    "    if conf_matrix.shape[1] != 1: #If given normal confusion matrix\n",
    "        _, ax = plt.subplots(figsize = (14, 12))\n",
    "    \n",
    "        sns.heatmap(conf_matrix, cmap = 'BuPu', annot = True, annot_kws = {'size': 18}, vmin = 0, vmax = 100)\n",
    "    \n",
    "        ax.set_xlabel(\"Predicted Labels\")\n",
    "        ax.set_xticklabels(class_labels)\n",
    "        ax.set_ylabel(\"True Labels\")\n",
    "        ax.set_yticklabels(class_labels)\n",
    "        ax.set_title(phase.capitalize() + \" Data Confusion Matrix\")\n",
    "\n",
    "        if save_figs:\n",
    "            file = phase.capitalize() + \"_Confusion_Matrix.png\"\n",
    "            \n",
    "            #Keep track of file\n",
    "            SAVED_FILES.append(file)\n",
    "            \n",
    "            plt.savefig(file)\n",
    "    \n",
    "        plt.show()\n",
    "    else: #If given modified diagonal confusion matrix\n",
    "        _, ax = plt.subplots(figsize = (4, 12))\n",
    "\n",
    "        sns.heatmap(conf_matrix, cmap = 'BuPu', annot = True, annot_kws = {'size': 18}, vmin = 0, vmax = 100)\n",
    "\n",
    "        ax.set_xticklabels([])\n",
    "        ax.set_yticklabels(class_labels)\n",
    "        ax.set_title(phase.capitalize() + \" Data: Diagonal +-1 Class\")\n",
    "\n",
    "        if save_figs:\n",
    "            file = phase.capitalize() + \"_Diagonal_+-1_Class.png\"\n",
    "\n",
    "            #Keep track of file\n",
    "            SAVED_FILES.append(file)\n",
    "            \n",
    "            plt.savefig(file)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087c989a-031e-4136-ae1b-5e70481e6ea3",
   "metadata": {},
   "source": [
    "`save_dataframe`: Saves the given dataframe using phase to differentiate.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`df`: DataFrame to save.\\\n",
    "&emsp;`phase`: The DataLoader phase this DataFrame belongs to. (i.e. \"train\", \"test\", \"validate\")\n",
    "\n",
    "If `save_figs` flag is set to True, this function will save the given DataFrame to a parquet file with the string given by `phase` appended to the beginning of the filename.\\\n",
    "Does nothing otherwise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b885a8e3-b761-459d-9c44-9901aeec66f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_dataframe(df, phase):\n",
    "    '''Saves given dataframe to file. Determines which dataloader was used to generate df using phase.'''\n",
    "    global SAVED_FILES\n",
    "    \n",
    "    if save_figs:\n",
    "        file = phase.capitalize() + \"_Prediction_Dataframe.parquet\"\n",
    "\n",
    "        #Keep track of file\n",
    "        SAVED_FILES.append(file)\n",
    "        \n",
    "        df.to_parquet(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8fcce2c-91c4-4ee7-9650-83af44d95228",
   "metadata": {},
   "source": [
    "`display_predictions`: Uses predictions made by `dataloader_predictions` to create plots showing images, what class they were predicted to be by the model, and what class they were actually labelled as.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`df`: The Pandas DataFrame produced by `dataloader_predictions`.\\\n",
    "&emsp;`phase`: The phase of the training data set being used. (i.e. \"train\", \"test\", \"validate\")\\\n",
    "&emsp;`rows`: The number of rows to use for the final display. Affects the total number of images to be predicted. <b>Default:</b> 5.\\\n",
    "&emsp;`cols`: The number of columns to use for the final display. Affects the total number of images to be predicted. <b>Default:</b> 3.\\\n",
    "&emsp;`incorrect_only`: Flag to determine whether or not to display only images that were incorrectly predicted. <b>Default:</b> False.\n",
    "\n",
    "If the `incorrect_only` flag is set to True, modify the DataFrame, `df`, to remove any entries where the model prediction and actual label for an image were the same. Otherwise, does not change the DataFrame.\\\n",
    "Randomly samples `rows` * `cols` number of images from `df`. Then, displays those images, the model predictions for them, and the human annotations for them on a labelled plot.\\\n",
    "If `save_figs` flag is True, displayed predictions are saved as pngs, with the `phase` and `incorrect_only` parameters determining filenames, and kept track of using `SAVED_FILES`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a55a28-ac05-4b27-88cb-ffbe88942e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_predictions(df, phase, rows = 5, cols = 3, incorrect_only = False):\n",
    "    '''Randomly select rows * cols number of images from each class in the dataloader and make predictions on those images.\n",
    "    Display the images and their true and predicted labels.\n",
    "    If incorrect_only is True, only images that were incorrectly predicted will be displayed.\n",
    "    Determine which dataloader to use based on phase.'''\n",
    "    global SAVED_FILES\n",
    "    \n",
    "    total_images = rows * cols\n",
    "    base_dir = TRAINING_DATA + phase + \"/\"\n",
    "    label_translation = {\n",
    "        0: \"0_Negative\",\n",
    "        1: \"1_Primordial\",\n",
    "        2: \"2_Transitional Primordial\",\n",
    "        3: \"3_Primary\",\n",
    "        4: \"4_Transitional Primary\",\n",
    "        5: \"5_Secondary\",\n",
    "        6: \"6_Multilayer\"\n",
    "    }\n",
    "\n",
    "    if incorrect_only: #If only looking for images that were incorrectly predicted\n",
    "        df = df[df[\"Prediction\"] == False]\n",
    "    \n",
    "    #Randomly sample total_images number of images from the DataFrame weighted so that each class is equally likely to be drawn\n",
    "    predictions = df.sample(total_images, weights = (df[\"True Class\"].value_counts()[0] / df[\"True Class\"].value_counts())[df[\"True Class\"]].values, ignore_index = True)\n",
    "    predictions = predictions[[\"Filename\", \"True Class\", \"Predicted Class\"]]\n",
    "    \n",
    "    fig, axes = plt.subplots(rows, cols, figsize = (cols * 5, rows * 5))\n",
    "\n",
    "    axes = axes.flat\n",
    "\n",
    "    #Plot each image\n",
    "    for ax, (image_file, true_class, pred_class) in zip(axes, predictions.values):\n",
    "        image = Image.open(image_file)\n",
    "        file_name = image_file.split(\"/\")[-1][:-4].split(\"_w\")\n",
    "\n",
    "        ax.imshow(image)\n",
    "        ax.set_title(file_name[0] + \"\\nw\" + file_name[1] + \"\\n\\nTrue Label: \" + label_translation[true_class] + \"\\nPredicted Label: \" + label_translation[pred_class] + \" (\" + str(true_class == pred_class) + \")\")\n",
    "\n",
    "    fig.set_tight_layout(True)\n",
    "\n",
    "    #Save plots if desired\n",
    "    if save_figs:\n",
    "        if incorrect_only:\n",
    "            file = phase.capitalize() + \"_Random_Image_Prediction_Results_Incorrect_Only.png\"\n",
    "\n",
    "            #Keep track of file\n",
    "            SAVED_FILES.append(file)\n",
    "            \n",
    "            plt.savefig(file)\n",
    "        else:\n",
    "            file = phase.capitalize() + \"_Random_Image_Prediciton_Results.png\"\n",
    "            \n",
    "            #Keep track of file\n",
    "            SAVED_FILES.append(file)\n",
    "            \n",
    "            plt.savefig(file)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7025c8-28f4-4e1a-8bf6-687d13ec8ce0",
   "metadata": {},
   "source": [
    "## Data and Model Setup\n",
    "\n",
    "This section contains the set up for the Datasets, DataLoaders, and image classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30545c3d-05af-47a0-8579-4d42fa9ac3d5",
   "metadata": {},
   "source": [
    "Set the device to use for PyTorch. Then print out the device to make sure it is using the correct one.\\\n",
    "&emsp;\"cuda\" = GPU, \"cpu\" = CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "739a2465-f231-4833-b2a6-aa12b646c52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Torch device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: {}\".format(device)) #Check torch device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf97b4e3-336f-4244-84e2-5131396bbb20",
   "metadata": {},
   "source": [
    "Create dictionaries that store the datasets and DataLoaders as well as their sizes for each subset of the training data (\"train\", \"test\", \"validate\").\n",
    "\n",
    "<b>Dictionary Structures:</b>\n",
    "```python\n",
    "image_datasets = {\n",
    "    'train': ImageFolderWithPaths object,\n",
    "    'test': ImageFolderWithPaths object,\n",
    "    'validate': ImageFolderWithPaths object\n",
    "}\n",
    "image_dataloaders = {\n",
    "    'train': DataLoader object,\n",
    "    'test': DataLoader object,\n",
    "    'validate': DataLoader object\n",
    "}\n",
    "image_dataset_sizes = {\n",
    "    'train': length of image_datasets['train'],\n",
    "    'test': length of image_datasets['test'],\n",
    "    'validate': length of image_datasets['validate']\n",
    "}\n",
    "image_dataloader_sizes = {\n",
    "    'train': length of image_dataloaders['train'],\n",
    "    'test': length of image_dataloaders['test'],\n",
    "    'validate': length of image_dataloaders['validate']\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "668cbe34-a2ac-4f7a-a866-1a770b4630ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create datasets and dataloaders\n",
    "image_datasets = {}\n",
    "image_dataloaders = {}\n",
    "image_dataset_sizes = {}\n",
    "image_dataloader_sizes = {}\n",
    "\n",
    "for phase in ['train', 'test', 'validate']:\n",
    "    image_datasets[phase] = ImageFolderWithPaths(TRAINING_DATA + phase + \"/\", transform = transform)\n",
    "    image_dataloaders[phase] = DataLoader(image_datasets[phase], batch_size = batch_size, shuffle = True, num_workers = num_workers, pin_memory = True)\n",
    "    image_dataset_sizes[phase] = len(image_datasets[phase])\n",
    "    image_dataloader_sizes[phase] = len(image_dataloaders[phase])\n",
    "\n",
    "print(\"Dataset Sizes: {}\\n\".format(image_dataset_sizes))\n",
    "print(\"Dataloader Sizes: {}\\n\".format(image_dataloader_sizes))\n",
    "\n",
    "#Define classes\n",
    "classes = image_datasets['train'].classes\n",
    "\n",
    "print(\"Classes: {}\".format(classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38f7992-7b48-4f51-b9be-115156cbc0f4",
   "metadata": {},
   "source": [
    "Determine the total number of images in the train subset of the training data. Also determine the number of images in each class of the train subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447bb8ea-8b34-46c9-918b-3e18a5085473",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Determine individual class sizes for, and total size of, training data\n",
    "class_sizes = {}\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    for _, _, files in os.walk(TRAINING_DATA + \"train/\" + classes[i] + \"/\"):\n",
    "        class_sizes[classes[i]] = len(files)\n",
    "\n",
    "print(\"Train Data Class Sizes: {}\".format(class_sizes))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd10c7b8-3757-4c71-bd52-2bc9546f9a75",
   "metadata": {},
   "source": [
    "Using the calculated class sizes, create weights for each class by dividing the number of image in the largest class by the number of images in each class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3abceab-662f-4b3b-9aa2-ff8099a6aaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate class weights for uneven class sizes\n",
    "class_weights = []\n",
    "\n",
    "for i in class_sizes.values():\n",
    "    class_weights.append(max(class_sizes.values()) / i)\n",
    "\n",
    "class_weights = torch.tensor(class_weights).to(device)\n",
    "\n",
    "print(\"Class Weights: {}\".format(class_weights))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb194953-db7c-48c2-8870-6cf72a01f55f",
   "metadata": {},
   "source": [
    "Call `setup_model` and pass it the pretrained ResNet34 to set up.\n",
    "\n",
    "If `use_class_weights` flag is True, create the loss function with the class weights. Otherwise, just create the loss function.\\\n",
    "The loss function used is CrossEntropyLoss.\n",
    "\n",
    "Create the optimizer, passing it `sgd_learning_rate`, `sgd_momentum`, and `sgd_weight_decay`.\\\n",
    "The optimizer used is SGD (Stochastic Gradient Descent)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f6f47c-3dab-4870-bab1-bdfb16c63b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model setup\n",
    "model = setup_model(models.resnet34(weights = \"ResNet34_Weights.DEFAULT\"), len(classes))\n",
    "\n",
    "#Loss function\n",
    "if use_class_weights:\n",
    "    criterion = nn.CrossEntropyLoss(weight = class_weights)\n",
    "else:\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "#Optimizer\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr = sgd_learning_rate, momentum = sgd_momentum, weight_decay = sgd_weight_decay)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a67c561-b7e3-4c03-a057-27e9c9f77886",
   "metadata": {},
   "source": [
    "## Main Code\n",
    "\n",
    "This section contains the main code of this notebook that trains the model and then analyzes it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "564ef526-8f27-4e29-8070-ef881fb7de1c",
   "metadata": {},
   "source": [
    "### Display some Training Images"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d01a9af-21ba-4142-ab75-d7c33b19e3e2",
   "metadata": {},
   "source": [
    "Pull 8 images from the train subset and display both the original image as well as the transformed image side by side."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd2025b-6212-483e-9edf-f49c23a770fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Display random images and their transformed counterparts\n",
    "for images, labels, file_paths in image_dataloaders['train']:\n",
    "    images = images.numpy()\n",
    "\n",
    "    cols = [\"Original Image\", \"Transformed Image\"]\n",
    "    rows = labels[:8]\n",
    "    \n",
    "    fig, ax = plt.subplots(8, 2, figsize = (8, 25))\n",
    "\n",
    "    for axis, col in zip(ax[0], cols):\n",
    "        axis.set_title(col)\n",
    "\n",
    "    for axis, row in zip(ax[:, 0], rows):\n",
    "        axis.set_ylabel(classes[row])\n",
    "\n",
    "    for i in range(8):\n",
    "        ax[i, 0].imshow(Image.open(file_paths[i]))\n",
    "        ax[i, 1].imshow(np.clip(np.transpose(images[i], (1, 2, 0)), a_min = 0, a_max = 1))\n",
    "\n",
    "    fig.tight_layout()\n",
    "    plt.show()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f448235a-06e9-40f2-be93-59cb7e0d963e",
   "metadata": {},
   "source": [
    "### Model Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab7a6b8-65c7-422e-a3d5-fb5d4e97dace",
   "metadata": {},
   "source": [
    "Train the model for `num_epochs` + 1 by calling `train_model` and passing it the model, loss function, and optimizer created earlier, as well as `num_epochs`.\\\n",
    "Once finished, plot the losses and accuracies using `train_test_graph`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7c13e9-68b2-4942-9ca7-2ae11e5d6d2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Train model\n",
    "losses, accuracies = train_model(model, criterion, optimizer, num_epochs = num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395c79c-ea92-4040-a1bf-140c76d59191",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph losses during training and testing\n",
    "train_test_graph(losses, \"Loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac1fdd7-5d3d-461e-8fd8-429c520c37af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graph accuracies during training and testing\n",
    "train_test_graph(accuracies, \"Accuracy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171f0137-f32f-4a5d-bb7f-a088eb4ec828",
   "metadata": {},
   "source": [
    "### Model Analysis and File Saving Per Epoch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30289ba-2689-49b1-a24e-a7a3dcaabdf8",
   "metadata": {},
   "source": [
    "If the `save_each_epoch` flag is set to True, iterate through each epoch using `num_epochs`. Also, iterate through each dataloader phase (\"train\", \"test\", \"validate\") per epoch. Make predictions on the dataloader and make confusion matrices from those predictions. Then, save the dataframe created by `dataloader_predictions` to a file. Print the classification report for the predictions made previously as well. Finally, display some randomly sampled images with their predictions and actual labels for comparison. Once all three phases are finished, create an output directory for the current epoch and move everything into it. Then, continue on to the next epoch. Once all epochs are finished, \"Done\" will be printed to the output.\n",
    "\n",
    "If the `save_each_epoch` flag is set to False, only iterate through the \"best_accuracy\" and \"best_loss\" checkpoints that were saved. Also, iterate through each dataloader phase (\"train\", \"test\", \"validate\") per checkpoint. Make predictions on the dataloader and make confusion matrices from those predictions. Then, save the dataframe created by `dataloader_predictions` to a file. Print the classification report for the predictions made previously as well. Finally, display some randomly sampled images with their predictions and actual labels for comparison. Once all three phases are finished, create an output directory for the current checkpoint and move everything into it. Then, continue on to the next checkpoint. Once both checkpoints are finished, \"Done\" will be printed to the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa30974-b273-419d-b035-29da7258b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "if save_each_epoch: #If a checkpoint was saved for each epoch during training\n",
    "    #Iterate over each epoch\n",
    "    for epoch in range(0, num_epochs + 1):\n",
    "        print(\"---------- Epoch: {} ----------\".format(epoch))\n",
    "        \n",
    "        #Load checkpoint for epoch\n",
    "        model.load_state_dict(torch.load(CHECKPOINT + str(epoch) + \".pt\", map_location = device, weights_only = True))\n",
    "    \n",
    "        #Iterate over each phase\n",
    "        for phase in ['train', 'test', 'validate']:\n",
    "            print(\"  ---------- Phase: {} ----------\".format(phase.capitalize()))\n",
    "            \n",
    "            #Make predictions\n",
    "            predicted_labels, true_labels, prediction_df = dataloader_predictions(phase)\n",
    "    \n",
    "            #Make and plot confusion matrices\n",
    "            make_confusion_matrix(predicted_labels, true_labels, phase)\n",
    "    \n",
    "            #Save prediction dataframe\n",
    "            save_dataframe(prediction_df, phase)\n",
    "    \n",
    "            #Classification report\n",
    "            print(classification_report(true_labels, predicted_labels))\n",
    "    \n",
    "            #Display random images and their predictions\n",
    "            display_predictions(prediction_df, phase)\n",
    "    \n",
    "            #Display random images that were incorrectly predicted\n",
    "            display_predictions(prediction_df, phase, incorrect_only = True)\n",
    "    \n",
    "        #Move outputs and save notebook for epoch\n",
    "        print(\"  ---------- Saving and Moving Files ----------\")\n",
    "        \n",
    "        #Create time-stamped output directory\n",
    "        make_output_dir(epoch = str(epoch))\n",
    "        print(\"    Output Dir: {}\".format(TIME_STAMP_OUTPUT_DIR))\n",
    "    \n",
    "        #Move output files to output directory\n",
    "        shutil.move(CHECKPOINT + str(epoch) + \".pt\", TIME_STAMP_OUTPUT_DIR)\n",
    "    \n",
    "        if len(SAVED_FILES) > 0:\n",
    "            for file in SAVED_FILES:\n",
    "                shutil.move(file, TIME_STAMP_OUTPUT_DIR)\n",
    "    \n",
    "        SAVED_FILES.clear()\n",
    "    \n",
    "        #Save notebook\n",
    "        APP.commands.execute(\"docmanager:save\")\n",
    "    \n",
    "        #Copy notebook to output directory\n",
    "        shutil.copy2(NOTEBOOK_NAME, TIME_STAMP_OUTPUT_DIR)\n",
    "    \n",
    "        #Clear cell output to avoid file save errors due to overflow\n",
    "        clear_output(wait = True)\n",
    "    \n",
    "    print(\"Done\")\n",
    "elif not save_each_epoch: #If checkpoints for only the best accuracy and loss epochs were saved during training\n",
    "    #Iterate over each checkpoint\n",
    "    for checkpoint in [\"best_accuracy\", \"best_loss\"]:\n",
    "        print(\"---------- Checkpoint: {} ----------\".format(checkpoint))\n",
    "        \n",
    "        #Load checkpoint\n",
    "        model.load_state_dict(torch.load(CHECKPOINT[:-6] + checkpoint + \".pt\", map_location = device, weights_only = True))\n",
    "    \n",
    "        #Iterate over each phase\n",
    "        for phase in ['train', 'test', 'validate']:\n",
    "            print(\"  ---------- Phase: {} ----------\".format(phase.capitalize()))\n",
    "            \n",
    "            #Make predictions\n",
    "            predicted_labels, true_labels, prediction_df = dataloader_predictions(phase)\n",
    "    \n",
    "            #Make and plot confusion matrices\n",
    "            make_confusion_matrix(predicted_labels, true_labels, phase)\n",
    "    \n",
    "            #Save prediction dataframe\n",
    "            save_dataframe(prediction_df, phase)\n",
    "    \n",
    "            #Classification report\n",
    "            print(classification_report(true_labels, predicted_labels))\n",
    "    \n",
    "            #Display random images and their predictions\n",
    "            display_predictions(prediction_df, phase)\n",
    "    \n",
    "            #Display random images that were incorrectly predicted\n",
    "            display_predictions(prediction_df, phase, incorrect_only = True)\n",
    "    \n",
    "        #Move outputs and save notebook for epoch\n",
    "        print(\"  ---------- Saving and Moving Files ----------\")\n",
    "        \n",
    "        #Create time-stamped output directory\n",
    "        make_output_dir(checkpoint = checkpoint)\n",
    "        print(\"    Output Dir: {}\".format(TIME_STAMP_OUTPUT_DIR))\n",
    "    \n",
    "        #Move output files to output directory\n",
    "        shutil.move(CHECKPOINT[:-6] + checkpoint + \".pt\", TIME_STAMP_OUTPUT_DIR)\n",
    "    \n",
    "        if len(SAVED_FILES) > 0:\n",
    "            for file in SAVED_FILES:\n",
    "                shutil.move(file, TIME_STAMP_OUTPUT_DIR)\n",
    "    \n",
    "        SAVED_FILES.clear()\n",
    "    \n",
    "        #Save notebook\n",
    "        APP.commands.execute(\"docmanager:save\")\n",
    "    \n",
    "        #Copy notebook to output directory\n",
    "        shutil.copy2(NOTEBOOK_NAME, TIME_STAMP_OUTPUT_DIR)\n",
    "    \n",
    "        #Clear cell output to avoid file save errors due to overflow\n",
    "        clear_output(wait = True)\n",
    "    \n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1a5422f-b5a9-4f16-a0de-a580c0ca1185",
   "metadata": {},
   "source": [
    "### Convert Notebook to HTML and Move to Output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ce71be2-d2b2-46ea-9a26-01a39e158d8e",
   "metadata": {},
   "source": [
    "Programmatically save the notebook using `APP`. (For some reason, the `time.sleep()` call is needed for the save command to properly execute)\\\n",
    "Then, convert the notebook to html and move it to the base `OUTPUT_DIR`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24574c4-6682-4805-8afc-7ef693d74e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For some reason, this is needed for the save command just below it to function\n",
    "time.sleep(1)\n",
    "\n",
    "#Save notebook\n",
    "APP.commands.execute(\"docmanager:save\")\n",
    "\n",
    "#Convert notebook to html\n",
    "!jupyter nbconvert --to html \"$NOTEBOOK_NAME\"\n",
    "\n",
    "#Move html to output directory\n",
    "shutil.move(NOTEBOOK_NAME[:-6] + \".html\", OUTPUT_DIR + NOTEBOOK_NAME[:-6] + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \".html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
