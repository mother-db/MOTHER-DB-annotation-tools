{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92a96c98-34a0-4430-aa55-f7cefa18288b",
   "metadata": {},
   "source": [
    "# Program 4 - Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0922243-2d46-4f6b-b908-b904035c5675",
   "metadata": {},
   "source": [
    "## Base Setup\n",
    "\n",
    "This section contains the basic environment set up for this notebook, including imports, constants, and any variable that needs to be easily accessed for changing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94ff7717-0e65-40bd-b838-119072368dbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import modules\n",
    "import cv2\n",
    "import os\n",
    "import shutil\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from ipylab import JupyterFrontEnd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "140269a2-b2e1-4bf4-8014-67a5430780f4",
   "metadata": {},
   "source": [
    "This is a set of constants used mainly for workspace setup.\n",
    "\n",
    "`OUTPUT_DIR`: The folder to create inside the INPUT_DIR where output files from this analysis program will be saved.\\\n",
    "`INPUT_DIR`: The relative or absolute path to the base directory containing the outputs from a Program 4 run that needs to be further analyzed.\\\n",
    "`SAMPLE_DIR`: The relative or absolute path to the directory containing the sample image(s).\\\n",
    "`SAMPLE_IMAGE_DICT`: A dictionary containing keys, which are the complete names of the sample image files, and their corresponding values, which are the complete names of the annotation files associated with those sample images. Currently, used mainly for testing purposes. Should be identical to the one used in the main Program 4.\\\n",
    "`COLOR_PALETTE`: A list containing colors to be used when visually plotting the prediction heatmaps. Each class has its own color. Should be identical to the one used in the main Program 4.\\\n",
    "`COLOR_OVERLAY_TRANSLATOR`: A dictionary whose keys are the colors in `COLOR_PALETTE` and values are the colors converted into separate RGB values.\\\n",
    "`NOTEBOOK_NAME`: The exact name of this notebook, including the file extension. Needed later for programmatic html conversion and copying of the notebook.\\\n",
    "`APP`: JupyterFrontEnd instance that is used to save the notebook programmatically later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58bc977c-3e68-46d4-b3df-0da6afcc02e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create constants\n",
    "OUTPUT_DIR = \"Analysis/\"\n",
    "INPUT_DIR = \"Output/Small Follicles/ResNet34/Run Final 1/\"\n",
    "SAMPLE_DIR = \"../../Data/Original/\"\n",
    "SAMPLE_IMAGE_DICT = {\n",
    "    \"14736_UN_050a.ome.tif\": \"14736_UN_050a.annotations.txt\",\n",
    "    \"16418_UN_140b.ome.tif\": \"16418_UN_140b.annotations.txt\",\n",
    "    \"19006_UN_020a.ome.tif\": \"19006_UN_020a.annotations.txt\",\n",
    "    \"21930_LT_060a.ome.tif\": \"21930_LT_060a_annotationsTable.txt\",\n",
    "    \"21930_LT_120b.ome.tif\": \"21930_LT_120b_annotationsTable.txt\",\n",
    "    \"25058_LT_005a.ome.tif\": \"25058_LT_005a.annotations.txt\",\n",
    "    \"25065_LT_010a.ome.tif\": \"25065_LT_010a.annotations.txt\",\n",
    "    \"25081_LT_010a.ome.tif\": \"25081_LT_010a.annotations.txt\",\n",
    "    \"27570_UN_110a.ome.tif\": \"27570_UN_110a.annotations.txt\",\n",
    "    \"30381_RT_070b.ome.tif\": \"30381_RT_070b.ome.annotationsTable.txt\",\n",
    "    \"30381_RT_140b.ome.tif\": \"30381_RT_140b.ome.annotationsTable.txt\",\n",
    "    \"30381_RT_200c.ome.tif\": \"30381_RT_200c.ome.annotationsTable.txt\",\n",
    "    \"32002_RT_050a.ome.tif\": \"32002_RT_050a.ome.annotationsTable.txt\",\n",
    "    \"32002_RT_110b.ome.tif\": \"32002_RT_110b.ome.annotationsTable.txt\",\n",
    "    \"32002_RT_160c.ome.tif\": \"32002_RT_160c.ome.annotationsTable.txt\",\n",
    "    \"33564_RT_060a.ome.tif\": \"33564_RT_060a.ome.annotationsTable.txt\",\n",
    "    \"33564_RT_120b.ome.tif\": \"33564_RT_120b.ome.annotationsTable.txt\",\n",
    "    \"33564_RT_180b.ome.tif\": \"33564_RT_180b.ome.annotationsTable.txt\",\n",
    "    \"DP28_25081_Section3_10X_ome_copy.tif\": \"DP28_25081_Section3_10X_ome_copy.annotations.txt\",\n",
    "    \"32002_LT_180a.ome.tif\": \"32002_LT_180a.ome.annotationsTable.txt\",\n",
    "    \"KY_PS_LB40SDwk16601_7_a.ome.tif\": \"LB40_SDwk16601_7a_annotationsTable.txt\"\n",
    "}\n",
    "COLOR_PALETTE = ['white', 'red', 'gold', 'blue', 'green', 'darkviolet', 'dimgray']\n",
    "COLOR_OVERLAY_TRANSLATOR = {\n",
    "    \"white\": [255, 255, 255],\n",
    "    \"red\": [255, 0, 0],\n",
    "    \"gold\": [255, 215, 0],\n",
    "    \"blue\": [0, 0, 255],\n",
    "    \"green\": [0, 128, 0],\n",
    "    \"darkviolet\": [148, 0, 211],\n",
    "    \"dimgray\": [105, 105, 105]\n",
    "}\n",
    "NOTEBOOK_NAME = \"Program 4 - Analysis Final v2.ipynb\"\n",
    "APP = JupyterFrontEnd()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca64ba0f-7a8d-4adc-8e86-4f4e81b3a042",
   "metadata": {},
   "source": [
    "These are variables and flags for functions that get used later.\n",
    "\n",
    "`multiple_epochs`: Flag to determine whether to run the analysis on every prediction for every epoch or just every prediction made. Should be identical to the value used in the run of Program 4 being analyzed.\\\n",
    "`save_figs`: A flag to determine whether this program will save any graphs/images it generates.\\\n",
    "`window_size`: The size of one side of the square window that was used for predictions. <b>Note:</b> Should be the same number used in Program 4 to make predictions.\\\n",
    "`window_radius`: The window radius to use when making predictions. Half of the `window_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae1e3d3-538b-49ce-a839-4b771ea5461e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create variables\n",
    "multiple_epochs = True\n",
    "\n",
    "save_figs = True\n",
    "\n",
    "window_size = 200\n",
    "window_radius = int(window_size / 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cca1fde-77a0-4b8d-848a-6df086c90c0b",
   "metadata": {},
   "source": [
    "### Function Definitions\n",
    "\n",
    "This section contains all the Functions used by this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e664b061-6336-490e-8128-5b2593416d03",
   "metadata": {},
   "source": [
    "`make_output_dir`: Creates the directory specified by the parameter `directory`.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`directory`: The directory path to create.\n",
    "\n",
    "First, checks if `directory` already exists. If it does, nothing happens. If it doesn't creates `directory`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edd24c8-8d3c-4309-ae1a-5ade97900844",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_output_dir(directory):\n",
    "    '''Check if the directory specified by OUTPUT_DIR exists inside INPUT_DIR. Create directory if it does not exist.'''\n",
    "    #Create base output directory if it does not exist\n",
    "    if not os.path.exists(directory):\n",
    "        os.mkdir(directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "971de873-cb3a-4795-93eb-48e0a5f5ebbf",
   "metadata": {},
   "source": [
    "`check_coord_bounds`: Checks if the coordinates contained in a dataframe are within certain bounds.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`df`: The dataframe containing coordinates.\\\n",
    "&emsp;`x`: A range object of the x bound.\\\n",
    "&emsp;`y`: A range object of the y bound.\\\n",
    "&emsp;`row_num`: The row number of the coordinates in the dataframe that are currently being looked at.\n",
    "\n",
    "<b>Returns:</b>\\\n",
    "&emsp;A boolean of whether the coordinates in the desired row of the dataframe are within the x, y bounds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a4d0f4-980a-4e10-934e-7c40416fed3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_coord_bounds(df, x, y, row_num):\n",
    "    '''Checks whether coordinates in a given row of a given dataframe are within the given x, y bounds.'''\n",
    "    return x[0] <= df['Centroid Y px'][row_num] <= x[-1] and y[0] <= df['Centroid X px'][row_num] <= y[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2158fef4-041f-4f26-b8eb-8bb9024aea35",
   "metadata": {},
   "source": [
    "`get_coords`: Gets the modified coordinates contained in a dataframe as a list.\n",
    "\n",
    "<b>Parameters:</b>\\\n",
    "&emsp;`df`: The dataframe containing coordinates.\\\n",
    "&emsp;`x`: A range object of the x bound.\\\n",
    "&emsp;`y`: A range object of the y bound.\\\n",
    "&emsp;`row_num`: The row number of the coordinates in the dataframe that are currently being looked at.\n",
    "\n",
    "<b>Returns:</b>\\\n",
    "&emsp;A list containing the coordinates in a row of the dataframe that have been modified to fit in the x and y range bounds where the beginning of those bounds are the new 0, 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2d4ceba-2b50-4b14-89e7-200f3a736265",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_coords(df, x, y, row_num):\n",
    "    '''Returns a list of coords from a given row of a given dataframe with the given x, y bounds subtracted to fit on a plot.'''\n",
    "    return list(df[['Centroid X px', 'Centroid Y px']].iloc[row_num].to_numpy() - np.array([y[0], x[0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cd8be3-2837-41d6-8d12-f0bee2af76e3",
   "metadata": {},
   "source": [
    "## Main Code\n",
    "\n",
    "This section contains the main code of the program that further analyses the predictions made in the main Program 4."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61c9863-ffeb-4c45-9312-a6dace1c626c",
   "metadata": {},
   "source": [
    "If the `multiple_epochs` flag is set to False, loop through the input directory, skipping anything that is not a directory. Then, loop through each directory from the first loop. Get the image that the directory from the first loop belongs to. Create an ouput directory inside the directory from the second loop. Load in the base image from `SAMPLE_DIR` and create the same whole image slice from the main Program 4 (Note: Smaller image slices are not currently supported by this program.) Also loads in the annotations for the sample image and converts them to a dictionary of annotation coordinates separated by follicle class. Next, load in the overlay image and add markers for every human annotation onto it. If `save_figs` is True, save the newly marked overlay image. Then, load in the predictions dataframe and convert it into a colored overlay matching the `COLOR_PALETTE`. Put this overlay onto the original image. If `save_figs` is True, save the newly created colored overlay image. Finally, add the human annotation markers to the colored overlay image. If `save_figs` is True, save the newly created annotated color overlay image. Save the notebook and copy it to the output directory.\n",
    "\n",
    "If the `multiple_epochs` flag is set to True, loop through the input directory, skipping everything that is not a directory. Then, loop through each epoch directory from the first loop. Next, loop through each image directory from the second loop. Then, loop through each directory inside the directory from the second loop. Get the image that the directory from the second loop belongs to. Create an ouput directory inside the directory from the third loop. Load in the base image from `SAMPLE_DIR` and create the same whole image slice from the main Program 4 (Note: Smaller image slices are not currently supported by this program.) Also loads in the annotations for the sample image and converts them to a dictionary of annotation coordinates separated by follicle class. Next, load in the overlay image and add markers for every human annotation onto it. If `save_figs` is True, save the newly marked overlay image. Then, load in the predictions dataframe and convert it into a colored overlay matching the `COLOR_PALETTE`. Put this overlay onto the original image. If `save_figs` is True, save the newly created colored overlay image. Finally, add the human annotation markers to the colored overlay image. If `save_figs` is True, save the newly created annotated color overlay image. Save the notebook and copy it to the output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38e516-f786-4eae-9898-08937dbbbaf6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if not multiple_epochs: #If only one epoch was used in the main program 4\n",
    "    #Loop through each image prediciton directory\n",
    "    for folder in sorted(os.listdir(INPUT_DIR)):\n",
    "        if os.path.isfile(INPUT_DIR + folder): #If the current item in the input directory is not a folder\n",
    "            continue\n",
    "    \n",
    "        #Loop through each time-stamped directory inside the image prediction directory\n",
    "        for subfolder in sorted(os.listdir(INPUT_DIR + folder + \"/\")):\n",
    "            #Find the key in SAMPLE_IMAGE_DICT that matches up to the current image prediction directory\n",
    "            for key in SAMPLE_IMAGE_DICT.keys():\n",
    "                if folder in key:\n",
    "                    break\n",
    "    \n",
    "            print(\"--- {} ---\".format(key))\n",
    "    \n",
    "            directory = INPUT_DIR + folder + \"/\" + subfolder + \"/\"\n",
    "            resolution = 0.1725 if key == \"DP28_25081_Section3_10X_ome_copy.tif\" else 0.69\n",
    "    \n",
    "            #Make the output directory\n",
    "            make_output_dir(directory + OUTPUT_DIR)\n",
    "            \n",
    "            #Load in the image and create a full image slice\n",
    "            image = cv2.cvtColor(cv2.imread(SAMPLE_DIR + key), cv2.COLOR_BGR2RGB)\n",
    "            \n",
    "            row_slice = range(window_radius, image.shape[0] - window_radius)\n",
    "            col_slice = range(window_radius, image.shape[1] - window_radius)\n",
    "    \n",
    "            image = image[row_slice[0]:row_slice[-1] + 1, col_slice[0]:col_slice[-1] + 1, :]\n",
    "    \n",
    "            #Load in the annotations and modify as needed\n",
    "            annotations = pd.read_csv(SAMPLE_DIR + SAMPLE_IMAGE_DICT[key], sep = \"\\t\")\n",
    "    \n",
    "            annotations[[\"Centroid X px\", \"Centroid Y px\"]] = annotations[['Centroid X µm', 'Centroid Y µm']] / resolution\n",
    "            annotations = annotations[['Name', 'Centroid X px', 'Centroid Y px']]\n",
    "            annotations.dropna(axis = 0, inplace = True, ignore_index = True)\n",
    "    \n",
    "            #Convert annotations to a coordinate dictionary of annotations\n",
    "            annot_coords = {\n",
    "                \"Primordial\": [[], COLOR_PALETTE[1]],\n",
    "                \"Transitional Primordial\": [[], COLOR_PALETTE[2]],\n",
    "                \"Primary\": [[], COLOR_PALETTE[3]],\n",
    "                \"Transitional Primary\": [[], COLOR_PALETTE[4]],\n",
    "                \"Secondary\": [[], COLOR_PALETTE[5]],\n",
    "                \"Multilayer\": [[], COLOR_PALETTE[6]]\n",
    "            }\n",
    "    \n",
    "            for i in range(len(annotations)):\n",
    "                annot_class = annotations['Name'][i]\n",
    "    \n",
    "                match annot_class:\n",
    "                    case 'Primordial':\n",
    "                        if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                            annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "                    case 'Transitional Primordial':\n",
    "                        if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                            annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "                    case 'Primary':\n",
    "                        if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                            annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "                    case 'Transitional Primary':\n",
    "                        if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                            annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "                    case 'Secondary':\n",
    "                        if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                            annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "                    case 'Multilayer':\n",
    "                        if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                            annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "    \n",
    "            #Load the overlay image\n",
    "            overlay = cv2.cvtColor(cv2.imread(directory + \"Overlay.png\"), cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "            #Draw the annotations onto the overlay image\n",
    "            for coords, color in annot_coords.values():\n",
    "                if len(coords) == 0:\n",
    "                    continue\n",
    "    \n",
    "                for x, y in coords:\n",
    "                    cv2.drawMarker(overlay, (int(x), int(y)), COLOR_OVERLAY_TRANSLATOR[color], markerType = cv2.MARKER_TILTED_CROSS, thickness = 5, markerSize = int((1 / image.shape[0]) * 500000))\n",
    "    \n",
    "            #Save the overlay image\n",
    "            if save_figs:\n",
    "                cv2.imwrite(directory + OUTPUT_DIR + \"Annotated_Overlay.png\", cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "                print(\"    - Saved Annotated_Overlay.png\")\n",
    "    \n",
    "            #Load the predictions dataframe\n",
    "            predictions = pd.read_parquet(directory + \"Predictions.parquet\")\n",
    "    \n",
    "            #Convert the predictions dataframe to a colored overlay\n",
    "            def colored_overlay(value):\n",
    "                match value:\n",
    "                    case 0.0:\n",
    "                        return COLOR_OVERLAY_TRANSLATOR['white']\n",
    "                    case 1.0:\n",
    "                        return COLOR_OVERLAY_TRANSLATOR['red']\n",
    "                    case 2.0:\n",
    "                        return COLOR_OVERLAY_TRANSLATOR['gold']\n",
    "                    case 3.0:\n",
    "                        return COLOR_OVERLAY_TRANSLATOR['blue']\n",
    "                    case 4.0:\n",
    "                        return COLOR_OVERLAY_TRANSLATOR['green']\n",
    "                    case 5.0:\n",
    "                        return COLOR_OVERLAY_TRANSLATOR['darkviolet']\n",
    "                    case 6.0:\n",
    "                        return COLOR_OVERLAY_TRANSLATOR['dimgray']\n",
    "    \n",
    "            predictions = np.asarray(predictions.map(colored_overlay).values.tolist(), dtype = np.uint8)\n",
    "    \n",
    "            #Put the colored overlay onto the original image and save\n",
    "            overlay_with_color = cv2.addWeighted(image, 0.7, predictions, 0.3, 0.0)\n",
    "\n",
    "            if save_figs:\n",
    "                cv2.imwrite(directory + OUTPUT_DIR + \"Colored_Overlay.png\", cv2.cvtColor(overlay_with_color, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "                print(\"    - Saved Colored_Overlay.png\")\n",
    "    \n",
    "            #Draw the annotations onto the colored overlay image\n",
    "            for coords, color in annot_coords.values():\n",
    "                if len(coords) == 0:\n",
    "                    continue\n",
    "    \n",
    "                for x, y in coords:\n",
    "                    cv2.drawMarker(overlay_with_color, (int(x), int(y)), COLOR_OVERLAY_TRANSLATOR[color], markerType = cv2.MARKER_TILTED_CROSS, thickness = 5, markerSize = int((1 / image.shape[0]) * 500000))\n",
    "    \n",
    "            #Save the annotated and colored overlay image\n",
    "            if save_figs:\n",
    "                cv2.imwrite(directory + OUTPUT_DIR + \"Annotated_Colored_Overlay.png\", cv2.cvtColor(overlay_with_color, cv2.COLOR_RGB2BGR))\n",
    "    \n",
    "                print(\"    - Saved Annotated_Colored_Overlay.png\")\n",
    "    \n",
    "            #Save the notebook\n",
    "            APP.commands.execute(\"docmanager:save\")\n",
    "    \n",
    "            #Copy the notebook to the output directory\n",
    "            shutil.copy2(NOTEBOOK_NAME, directory + OUTPUT_DIR)\n",
    "    \n",
    "            print(\"    - Saved and copied {}\".format(NOTEBOOK_NAME))\n",
    "        print()\n",
    "    print(\"Done\")\n",
    "elif multiple_epochs: #If multiple epochs were used in the main program 4\n",
    "    #Loop through each epoch directory\n",
    "    for epoch_dir in os.listdir(INPUT_DIR):\n",
    "        if os.path.isfile(INPUT_DIR + epoch_dir): #If the current item in the input directory is not a folder\n",
    "            continue\n",
    "\n",
    "        #Loop through each image prediciton directory\n",
    "        for folder in os.listdir(INPUT_DIR + epoch_dir + \"/\"):\n",
    "            if os.path.isfile(INPUT_DIR + epoch_dir + \"/\" + folder): #If the current item in the epoch directory is not a folder\n",
    "                continue\n",
    "        \n",
    "            #Loop through each time-stamped directory inside the image prediction directory\n",
    "            for subfolder in os.listdir(INPUT_DIR + epoch_dir + \"/\" + folder + \"/\"):\n",
    "                #Find the key in SAMPLE_IMAGE_DICT that matches up to the current image prediction directory\n",
    "                for key in SAMPLE_IMAGE_DICT.keys():\n",
    "                    if folder in key:\n",
    "                        break\n",
    "        \n",
    "                print(\"--- {} - {} ---\".format(epoch_dir, key))\n",
    "        \n",
    "                directory = INPUT_DIR + epoch_dir + \"/\" + folder + \"/\" + subfolder + \"/\"\n",
    "                resolution = 0.1725 if key == \"DP28_25081_Section3_10X_ome_copy.tif\" else 0.69\n",
    "        \n",
    "                #Make the output directory\n",
    "                make_output_dir(directory + OUTPUT_DIR)\n",
    "                \n",
    "                #Load in the image and create a full image slice\n",
    "                image = cv2.cvtColor(cv2.imread(SAMPLE_DIR + key), cv2.COLOR_BGR2RGB)\n",
    "                \n",
    "                row_slice = range(window_radius, image.shape[0] - window_radius)\n",
    "                col_slice = range(window_radius, image.shape[1] - window_radius)\n",
    "        \n",
    "                image = image[row_slice[0]:row_slice[-1] + 1, col_slice[0]:col_slice[-1] + 1, :]\n",
    "        \n",
    "                #Load in the annotations and modify as needed\n",
    "                annotations = pd.read_csv(SAMPLE_DIR + SAMPLE_IMAGE_DICT[key], sep = \"\\t\")\n",
    "        \n",
    "                annotations[[\"Centroid X px\", \"Centroid Y px\"]] = annotations[['Centroid X µm', 'Centroid Y µm']] / resolution\n",
    "                annotations = annotations[['Name', 'Centroid X px', 'Centroid Y px']]\n",
    "                annotations.dropna(axis = 0, inplace = True, ignore_index = True)\n",
    "        \n",
    "                #Convert annotations to a coordinate dictionary of annotations\n",
    "                annot_coords = {\n",
    "                    \"Primordial\": [[], COLOR_PALETTE[1]],\n",
    "                    \"Transitional Primordial\": [[], COLOR_PALETTE[2]],\n",
    "                    \"Primary\": [[], COLOR_PALETTE[3]],\n",
    "                    \"Transitional Primary\": [[], COLOR_PALETTE[4]],\n",
    "                    \"Secondary\": [[], COLOR_PALETTE[5]],\n",
    "                    \"Multilayer\": [[], COLOR_PALETTE[6]]\n",
    "                }\n",
    "        \n",
    "                for i in range(len(annotations)):\n",
    "                    annot_class = annotations['Name'][i]\n",
    "        \n",
    "                    match annot_class:\n",
    "                        case 'Primordial':\n",
    "                            if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                                annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "                        case 'Transitional Primordial':\n",
    "                            if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                                annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "                        case 'Primary':\n",
    "                            if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                                annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "                        case 'Transitional Primary':\n",
    "                            if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                                annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "                        case 'Secondary':\n",
    "                            if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                                annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "                        case 'Multilayer':\n",
    "                            if check_coord_bounds(annotations, row_slice, col_slice, i):\n",
    "                                annot_coords[annot_class][0].append(get_coords(annotations, row_slice, col_slice, i))\n",
    "        \n",
    "                #Load the overlay image\n",
    "                overlay = cv2.cvtColor(cv2.imread(directory + \"Overlay.png\"), cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "                #Draw the annotations onto the overlay image\n",
    "                for coords, color in annot_coords.values():\n",
    "                    if len(coords) == 0:\n",
    "                        continue\n",
    "        \n",
    "                    for x, y in coords:\n",
    "                        cv2.drawMarker(overlay, (int(x), int(y)), COLOR_OVERLAY_TRANSLATOR[color], markerType = cv2.MARKER_TILTED_CROSS, thickness = 5, markerSize = int((1 / image.shape[0]) * 500000))\n",
    "        \n",
    "                #Save the overlay image\n",
    "                if save_figs:\n",
    "                    cv2.imwrite(directory + OUTPUT_DIR + \"Annotated_Overlay.png\", cv2.cvtColor(overlay, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "                    print(\"    - Saved Annotated_Overlay.png\")\n",
    "        \n",
    "                #Load the predictions dataframe\n",
    "                predictions = pd.read_parquet(directory + \"Predictions.parquet\")\n",
    "        \n",
    "                #Convert the predictions dataframe to a colored overlay\n",
    "                def colored_overlay(value):\n",
    "                    match value:\n",
    "                        case 0.0:\n",
    "                            return COLOR_OVERLAY_TRANSLATOR['white']\n",
    "                        case 1.0:\n",
    "                            return COLOR_OVERLAY_TRANSLATOR['red']\n",
    "                        case 2.0:\n",
    "                            return COLOR_OVERLAY_TRANSLATOR['gold']\n",
    "                        case 3.0:\n",
    "                            return COLOR_OVERLAY_TRANSLATOR['blue']\n",
    "                        case 4.0:\n",
    "                            return COLOR_OVERLAY_TRANSLATOR['green']\n",
    "                        case 5.0:\n",
    "                            return COLOR_OVERLAY_TRANSLATOR['darkviolet']\n",
    "                        case 6.0:\n",
    "                            return COLOR_OVERLAY_TRANSLATOR['dimgray']\n",
    "        \n",
    "                predictions = np.asarray(predictions.map(colored_overlay).values.tolist(), dtype = np.uint8)\n",
    "        \n",
    "                #Put the colored overlay onto the original image and save\n",
    "                overlay_with_color = cv2.addWeighted(image, 0.7, predictions, 0.3, 0.0)\n",
    "\n",
    "                if save_figs:\n",
    "                    cv2.imwrite(directory + OUTPUT_DIR + \"Colored_Overlay.png\", cv2.cvtColor(overlay_with_color, cv2.COLOR_RGB2BGR))\n",
    "            \n",
    "                    print(\"    - Saved Colored_Overlay.png\")\n",
    "        \n",
    "                #Draw the annotations onto the colored overlay image\n",
    "                for coords, color in annot_coords.values():\n",
    "                    if len(coords) == 0:\n",
    "                        continue\n",
    "        \n",
    "                    for x, y in coords:\n",
    "                        cv2.drawMarker(overlay_with_color, (int(x), int(y)), COLOR_OVERLAY_TRANSLATOR[color], markerType = cv2.MARKER_TILTED_CROSS, thickness = 5, markerSize = int((1 / image.shape[0]) * 500000))\n",
    "        \n",
    "                #Save the annotated and colored overlay image\n",
    "                if save_figs:\n",
    "                    cv2.imwrite(directory + OUTPUT_DIR + \"Annotated_Colored_Overlay.png\", cv2.cvtColor(overlay_with_color, cv2.COLOR_RGB2BGR))\n",
    "        \n",
    "                    print(\"    - Saved Annotated_Colored_Overlay.png\")\n",
    "        \n",
    "                #Save the notebook\n",
    "                APP.commands.execute(\"docmanager:save\")\n",
    "        \n",
    "                #Copy the notebook to the output directory\n",
    "                shutil.copy2(NOTEBOOK_NAME, directory + OUTPUT_DIR)\n",
    "        \n",
    "                print(\"    - Saved and copied {}\".format(NOTEBOOK_NAME))\n",
    "            print()\n",
    "    print(\"Done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd2a96c6-f45c-49cb-b447-25ab54183883",
   "metadata": {},
   "source": [
    "### Convert Notebook to HTML and Move to Output Directory / Clean Up Working Directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aec68a9-38c1-4999-8cca-b0d0d765918c",
   "metadata": {},
   "source": [
    "Programmatically save the notebook, convert it to html and move the html file to the base input directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f8c7fbf-d654-48e4-8bde-68570bd0bd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Needed for the next command to work, for some reason\n",
    "time.sleep(1)\n",
    "\n",
    "#Programmatically save the notebook\n",
    "APP.commands.execute(\"docmanager:save\")\n",
    "\n",
    "#Convert the notebook to html\n",
    "!jupyter nbconvert --to html \"$NOTEBOOK_NAME\"\n",
    "\n",
    "#Move the html file to the input directory\n",
    "shutil.move(NOTEBOOK_NAME[:-6] + \".html\", INPUT_DIR + NOTEBOOK_NAME[:-6] + \"_\" + datetime.datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\") + \".html\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
